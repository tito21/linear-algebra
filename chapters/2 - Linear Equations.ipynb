{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "631565aa",
   "metadata": {},
   "source": [
    "# Linear Equations\n",
    "\n",
    "\n",
    "## Matrix-Matrix Multiplication\n",
    "\n",
    "Before diving into methods for solving linear equations, we need to define a new operation the matrix-matrix multiplication. This operation takes two matrices and produces a third matrix. Given a matrix $\\mathbf{A}$ of size $m \\times n$ and a matrix $\\mathbf{B}$ of size $n \\times p$, their product $\\mathbf{C} = \\mathbf{A}\\mathbf{B}$ is a matrix of size $m \\times p$. The element in the i-th row and j-th column of $\\mathbf{C}$, denoted as $c_{ij}$, is computed as the dot product of the i-th row of $\\mathbf{A}$ and the j-th column of $\\mathbf{B}$:\n",
    "$$c_{ij} = \\sum_{k=1}^{n} a_{ik} b_{kj}$$\n",
    "\n",
    "This can be implemented in Python as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf06694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of A @ B:\n",
      "[[ 58.  64.]\n",
      " [139. 154.]]\n",
      "[[ 58  64]\n",
      " [139 154]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def matrix_matrix_multiply(A, B):\n",
    "    \"\"\"Multiplies matrix A by a matrix B.\"\"\"\n",
    "\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    p = B.shape[1]\n",
    "    assert n == B.shape[0], \"Incompatible dimensions for matrix multiplication.\"\n",
    "\n",
    "    C = np.zeros((m, p))\n",
    "\n",
    "    for i in range(m):\n",
    "        for j in range(p):\n",
    "            for k in range(n):\n",
    "                C[i, j] += A[i, k] * B[k, j]\n",
    "\n",
    "    return C\n",
    "\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6]])\n",
    "B = np.array([[7, 8],\n",
    "              [9, 10],\n",
    "              [11, 12]])\n",
    "\n",
    "C = matrix_matrix_multiply(A, B)\n",
    "print(\"Result of A @ B:\")\n",
    "print(C)\n",
    "print(A @ B)  # Verify with NumPy's built-in function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311bf3ae",
   "metadata": {},
   "source": [
    "Note that you can use NumPy's built-in function `np.dot()` or the `@` operator for matrix multiplication, which are optimized for performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e659f6",
   "metadata": {},
   "source": [
    "## Gaussian Elimination\n",
    "\n",
    "From the last chapter, we know that a system of linear equations can be represented in matrix form as: $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$.\n",
    "\n",
    "In a system of two equations with two variables, this can be expressed as:\n",
    "\n",
    "$$\\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix}$$\n",
    "$$\\begin{cases} a_{11}x_1 + a_{12}x_2 = b_1 \\\\ a_{21}x_1 + a_{22}x_2 = b_2 \\end{cases}$$\n",
    "\n",
    "Which you probably already know how to solve by substitution or elimination. However, as the number of equations and variables increases, it becomes impractical to solve these systems by hand. Instead, we can develop algorithms to solve them more efficiently.\n",
    "\n",
    "Start by eliminating the first variable, $x_1$, from the second equation. To do this, we can multiply the first equation by $\\frac{a_{21}}{a_{11}}$ and subtract it from the second equation:\n",
    "\n",
    "$$\\begin{cases} a_{11}x_1 + a_{12}x_2 = b_1 \\\\ \\left(a_{21} - \\frac{a_{21}}{a_{11}}a_{11}\\right)x_1 + \\left(a_{22} - \\frac{a_{21}}{a_{11}}a_{12}\\right)x_2 = b_2 - \\frac{a_{21}}{a_{11}}b_1 \\end{cases}$$\n",
    "\n",
    "This simplifies to:\n",
    "\n",
    "$$\\begin{cases} a_{11}x_1 + a_{12}x_2 = b_1 \\\\ \\left(a_{22} - \\frac{a_{21}a_{12}}{a_{11}}\\right)x_2 = b_2 - \\frac{a_{21}}{a_{11}}b_1 \\end{cases}$$\n",
    "\n",
    "At this point, we can solve for $x_2$ directly from the second equation and then substitute back to find $x_1$. Then we have, $x_2 = \\frac{b_2 - \\frac{a_{21}}{a_{11}}b_1}{a_{22} - \\frac{a_{21}a_{12}}{a_{11}}}$ and $x_1 = b_1 - a_{12}x_2$.\n",
    "\n",
    "This can be repeated for a larger system of equations, by systematically eliminating variables from the equations below them, a process known as Gaussian elimination. Once in upper triangular form, we can then perform back substitution to find the values of the variables. In general for an $n \\times n$ system, the algorithm can be summarized as follows:\n",
    "\n",
    "1. For each row $i$ from 1 to $n-1$:\n",
    "   - For each row $j$ from $i+1$ to $n$:\n",
    "     - Compute the multiplier $m = \\frac{a_{ji}}{a_{ii}}$\n",
    "     - Update row $j$: \n",
    "       - $a_{jk} = a_{jk} - m \\cdot a_{ik}$ for all columns $k$ from $i$ to $n$\n",
    "       - $b_j = b_j - m \\cdot b_i$\n",
    "2. After obtaining the upper triangular matrix, perform back substitution:\n",
    "    - For each row $i$ from $n$ down to 1:\n",
    "      - Compute $x_i = \\frac{b_i - \\sum_{j=i+1}^{n} a_{ij} x_j}{a_{ii}}$\n",
    "\n",
    "This method can be implemented in Python as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05169bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: [-3.14285714 -3.31168831  5.92207792]\n",
      "Verification (Ax): [  8. -11.  -3.] should equal b: [  8 -11  -3]\n",
      "Close to Numpy solution: True\n"
     ]
    }
   ],
   "source": [
    "def gaussian_elimination(A, b):\n",
    "    \"\"\"Solves the system of linear equations Ax = b using Gaussian elimination.\n",
    "\n",
    "    Args:\n",
    "        A (np.ndarray): Coefficient matrix (n x n).\n",
    "        b (np.ndarray): Right-hand side vector (n,).\n",
    "    Returns:\n",
    "        x (np.ndarray): Solution vector (n,).\n",
    "    \"\"\"\n",
    "    n = len(b)\n",
    "    # Convert to float for division\n",
    "    A = A.astype(float)\n",
    "    b = b.astype(float)\n",
    "    # Forward elimination\n",
    "    for i in range(n - 1): # for each pivot row\n",
    "        for j in range(i + 1, n): # for each row below pivot\n",
    "            multiplier = A[j, i] / A[i, i]\n",
    "            A[j, i:] -= multiplier * A[i, i:]\n",
    "            b[j] -= multiplier * b[i]\n",
    "    # Back substitution\n",
    "    x = np.zeros(n)\n",
    "    for i in range(n - 1, -1, -1): # from last row to first\n",
    "        x[i] = (b[i] - np.dot(A[i, i+1:], x[i+1:])) / A[i, i]\n",
    "    return x\n",
    "\n",
    "# Example usage\n",
    "A = np.array([[1, 2, 3],\n",
    "              [2, 5, 2],\n",
    "              [6, -3, 1]])\n",
    "b = np.array([8, -11, -3])\n",
    "x = gaussian_elimination(A, b)\n",
    "print(\"Solution:\", x)\n",
    "print(\"Verification (Ax):\", A @ x, \"should equal b:\", b)\n",
    "print(\"Close to Numpy solution:\", np.allclose(x, np.linalg.solve(A, b)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1acada",
   "metadata": {},
   "source": [
    "Often in practical applications, we need to solve multiple systems of equations with the same coefficient matrix $\\mathbf{A}$ but different right-hand side vectors $\\mathbf{b}$. In such cases, it is efficient to perform the LU decomposition of $\\mathbf{A}$ once and then use it to solve for each $\\mathbf{b}$. The LU decomposition factors the matrix $\\mathbf{A}$ into a lower triangular matrix $\\mathbf{L}$ and an upper triangular matrix $\\mathbf{U}$ such that $\\mathbf{A} = \\mathbf{L}\\mathbf{U}$. Then, for each right-hand side vector $\\mathbf{b}$, we can solve the two triangular systems $\\mathbf{L}\\mathbf{y} = \\mathbf{b}$ and $\\mathbf{U}\\mathbf{x} = \\mathbf{y}$ using forward and backward substitution, respectively. This approach significantly reduces computational effort when solving multiple systems with the same coefficient matrix.\n",
    "\n",
    "The U matrix we already have from Gaussian elimination. To get the L matrix, we can keep track of the multipliers used during the elimination process. The multipliers form the entries of the L matrix below the main diagonal, while the diagonal entries of L are all 1s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55354e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L matrix:\n",
      " [[  1.   0.   0.]\n",
      " [  2.   1.   0.]\n",
      " [  6. -15.   1.]]\n",
      "U matrix:\n",
      " [[  1.   2.   3.]\n",
      " [  0.   1.  -4.]\n",
      " [  0.   0. -77.]]\n",
      "Verification (LU):\n",
      " [[ 1.  2.  3.]\n",
      " [ 2.  5.  2.]\n",
      " [ 6. -3.  1.]] should equal A:\n",
      " [[ 1  2  3]\n",
      " [ 2  5  2]\n",
      " [ 6 -3  1]]\n",
      "Solution using LU: [-3.14285714 -3.31168831  5.92207792]\n",
      "Close to Numpy solution: True\n"
     ]
    }
   ],
   "source": [
    "def LU_decomposition(A):\n",
    "    n = A.shape[0]\n",
    "    L = np.eye(n)\n",
    "    U = A.astype(float)\n",
    "    for i in range(n - 1):\n",
    "        for j in range(i + 1, n):\n",
    "            multiplier = U[j, i] / U[i, i]\n",
    "            L[j, i] = multiplier\n",
    "            U[j, i:] -= multiplier * U[i, i:]\n",
    "    return L, U\n",
    "\n",
    "def solve_LU(L, U, b):\n",
    "    n = len(b)\n",
    "    # Forward substitution to solve Ly = b\n",
    "    y = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        y[i] = b[i] - np.dot(L[i, :i], y[:i])\n",
    "    # Back substitution to solve Ux = y\n",
    "    x = np.zeros(n)\n",
    "    for i in range(n - 1, -1, -1):\n",
    "        x[i] = (y[i] - np.dot(U[i, i+1:], x[i+1:])) / U[i, i]\n",
    "    return x\n",
    "\n",
    "# Example usage of LU decomposition\n",
    "A = np.array([[1, 2, 3],\n",
    "              [2, 5, 2],\n",
    "              [6, -3, 1]])\n",
    "b = np.array([8, -11, -3])\n",
    "L, U = LU_decomposition(A)\n",
    "print(\"L matrix:\\n\", L)\n",
    "print(\"U matrix:\\n\", U)\n",
    "print(\"Verification (LU):\\n\", L @ U, \"should equal A:\\n\", A)\n",
    "x = solve_LU(L, U, b)\n",
    "print(\"Solution using LU:\", x)\n",
    "print(\"Close to Numpy solution:\", np.allclose(x, np.linalg.solve(A, b)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62af5f7",
   "metadata": {},
   "source": [
    "This algorithm works well for almost all systems of linear equations, except in cases where one of the pivot elements (the diagonal elements during elimination) is zero. For example, consider the system:\n",
    "$$\\begin{bmatrix} 0 & 2 \\\\ 1 & 3 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 4 \\\\ 5 \\end{bmatrix}$$\n",
    "\n",
    "The first pivot is zero, which will give a division by zero error during elimination. To handle such cases, we can use partial pivoting, which involves swapping rows to ensure that the pivot element is non-zero. We will be using the $\\mathbf{PA} = \\mathbf{LU}$ where $\\mathbf{P}$ is a permutation matrix that accounts for the row swaps. A permutation matrix is obtained by permuting the rows of an identity matrix. For example, swapping the first and second rows of a $2 \\times 2$ identity matrix gives:\n",
    "$$\\mathbf{P} = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}$$\n",
    "\n",
    "Also, for numerical stability, it is common to choose the largest available pivot element in absolute value from the column being considered. This helps to minimize rounding errors during the elimination process.\n",
    "\n",
    "Here's how we can implement Gaussian elimination with partial pivoting in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5decb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P matrix:\n",
      " [[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n",
      "L matrix:\n",
      " [[1.         0.         0.        ]\n",
      " [0.33333333 1.         0.        ]\n",
      " [0.16666667 0.41666667 1.        ]]\n",
      "U matrix:\n",
      " [[ 6.         -3.          1.        ]\n",
      " [ 0.          6.          1.66666667]\n",
      " [ 0.          0.          2.13888889]]\n",
      "Verification (LU):\n",
      " [[ 6. -3.  1.]\n",
      " [ 2.  5.  2.]\n",
      " [ 1.  2.  3.]] should equal L @ U:\n",
      " [[ 6. -3.  1.]\n",
      " [ 2.  5.  2.]\n",
      " [ 1.  2.  3.]]\n",
      "Solution using LU with pivoting: [-3.14285714 -3.31168831  5.92207792]\n",
      "Close to Numpy solution: True\n"
     ]
    }
   ],
   "source": [
    "def lu_decomposition_with_pivoting(A):\n",
    "    n = A.shape[0]\n",
    "    L = np.eye(n)\n",
    "    U = A.astype(float)\n",
    "    P = np.eye(n)\n",
    "    for i in range(n - 1):\n",
    "        # Pivoting\n",
    "        max_row_index = np.argmax(np.abs(U[i:, i])) + i\n",
    "        if max_row_index != i:\n",
    "            U[[i, max_row_index], :] = U[[max_row_index, i], :]\n",
    "            P[[i, max_row_index], :] = P[[max_row_index, i], :]\n",
    "            if i > 0:\n",
    "                L[[i, max_row_index], :i] = L[[max_row_index, i], :i]\n",
    "        for j in range(i + 1, n):\n",
    "            multiplier = U[j, i] / U[i, i]\n",
    "            L[j, i] = multiplier\n",
    "            U[j, i:] -= multiplier * U[i, i:]\n",
    "    return P, L, U\n",
    "\n",
    "def solve_LU_with_pivoting(P, L, U, b):\n",
    "    # Apply permutation to b\n",
    "    b = P @ b\n",
    "    n = len(b)\n",
    "    # Forward substitution to solve Ly = b\n",
    "    y = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        y[i] = b[i] - np.dot(L[i, :i], y[:i])\n",
    "    # Back substitution to solve Ux = y\n",
    "    x = np.zeros(n)\n",
    "    for i in range(n - 1, -1, -1):\n",
    "        x[i] = (y[i] - np.dot(U[i, i+1:], x[i+1:])) / U[i, i]\n",
    "    return x\n",
    "\n",
    "# Example usage of LU decomposition with pivoting\n",
    "A = np.array([[1, 2, 3],\n",
    "              [2, 5, 2],\n",
    "              [6, -3, 1]])\n",
    "b = np.array([8, -11, -3])\n",
    "P, L, U = lu_decomposition_with_pivoting(A)\n",
    "print(\"P matrix:\\n\", P)\n",
    "print(\"L matrix:\\n\", L)\n",
    "print(\"U matrix:\\n\", U)\n",
    "print(\"Verification (LU):\\n\", P @ A, \"should equal L @ U:\\n\", L @ U)\n",
    "x = solve_LU_with_pivoting(P, L, U, b)\n",
    "print(\"Solution using LU with pivoting:\", x)\n",
    "print(\"Close to Numpy solution:\", np.allclose(x, np.linalg.solve(A, b)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c95c92",
   "metadata": {},
   "source": [
    "## Matrix Inverses\n",
    "\n",
    "Not used often in numerical methods, but still important to understand is the matrix inverse. The inverse of a square matrix $\\mathbf{A}$, denoted as $\\mathbf{A}^{-1}$, is defined such that:\n",
    "$$\\mathbf{A}\\mathbf{A}^{-1} = \\mathbf{A}^{-1}\\mathbf{A} = \\mathbf{I}$$\n",
    "\n",
    "Matrix inverses can also be used to solve systems of linear equations. If $\\mathbf{A}$ is invertible, the solution to the system $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$ can be found by multiplying both sides by $\\mathbf{A}^{-1}$:\n",
    "$$\\mathbf{A}^{-1}\\mathbf{A}\\mathbf{x} = \\mathbf{A}^{-1}\\mathbf{b}$$\n",
    "$$\\mathbf{x} = \\mathbf{A}^{-1}\\mathbf{b}$$\n",
    "\n",
    "To compute the inverse of a matrix using Gaussian elimination, we can augment the matrix $\\mathbf{A}$ with the identity matrix $\\mathbf{I}$ and perform row operations to transform $\\mathbf{A}$ into $\\mathbf{I}$. The augmented part will then become $\\mathbf{A}^{-1}$. Here's how we can implement this in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c72e2fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse of A:\n",
      " [[-0.75   0.875]\n",
      " [ 0.25  -0.125]]\n",
      "Verification (A @ A_inv):\n",
      " [[1. 0.]\n",
      " [0. 1.]] should equal identity matrix:\n",
      " [[1. 0.]\n",
      " [0. 1.]]\n",
      "Close to Numpy inverse: True\n"
     ]
    }
   ],
   "source": [
    "def matrix_inverse(A):\n",
    "    n = A.shape[0]\n",
    "    # Create an augmented matrix [A | I]\n",
    "    A = A.astype(float)\n",
    "    AI = np.hstack((A, np.eye(n)))\n",
    "\n",
    "    for i in range(n):\n",
    "        # Make the diagonal contain all 1s\n",
    "        AI[i] = AI[i] / AI[i, i]\n",
    "\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                AI[j] = AI[j] - AI[j, i] * AI[i]\n",
    "\n",
    "    # The right half of the augmented matrix is now A^-1\n",
    "    A_inv = AI[:, n:]\n",
    "    return A_inv\n",
    "\n",
    "# Example usage of matrix inverse\n",
    "A = np.array([[1, 7],\n",
    "              [2, 6]])\n",
    "A_inv = matrix_inverse(A)\n",
    "print(\"Inverse of A:\\n\", A_inv)\n",
    "print(\"Verification (A @ A_inv):\\n\", A @ A_inv, \"should equal identity matrix:\\n\", np.eye(A.shape[0]))\n",
    "print(\"Close to Numpy inverse:\", np.allclose(A_inv, np.linalg.inv(A)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303511a7",
   "metadata": {},
   "source": [
    "## Linear Equations\n",
    "\n",
    "Now that we know how to solve linear equations we can proceed to discuss the different types of solutions that can arise when solving systems of linear equations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linear-algebra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
